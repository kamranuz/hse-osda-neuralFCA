{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuicenOBvdEQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title install libs\n",
        "\n",
        "!pip install fcapy[all]\n",
        "!pip install frozendict\n",
        "!pip install ipynb\n",
        "!pip install sparselinear\n",
        "!pip install bitsets\n",
        "!pip install bitarray\n",
        "import torch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "1VQyD97tGPuk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title import libs\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, jaccard_score, recall_score, accuracy_score, classification_report\n",
        "\n",
        "from fcapy.context import FormalContext\n",
        "from fcapy.lattice import ConceptLattice\n",
        "\n",
        "from fcapy.visualizer import LineVizNx\n",
        "import neural_lib as nl\n",
        "from fcapy.utils.utils import powerset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = (1,1,1,1)\n",
        "\n",
        "\n",
        "from fcapy import LIB_INSTALLED\n",
        "if LIB_INSTALLED['numpy']:\n",
        "    import numpy as np\n",
        "\n",
        "from sparselinear import SparseLinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y-UL4s6Ejr1",
        "outputId": "9731683b-7069-41cd-edfd-6659c5205116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting neural_lib.py\n"
          ]
        }
      ],
      "source": [
        "# @title neural_lib.py\n",
        "%%writefile neural_lib.py\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, FrozenSet, Set, Dict\n",
        "import pandas as pd\n",
        "\n",
        "from fcapy.lattice import ConceptLattice\n",
        "from fcapy.lattice.formal_concept import FormalConcept\n",
        "from fcapy.poset import POSet\n",
        "from fcapy.visualizer.line_layouts import calc_levels\n",
        "\n",
        "import torch\n",
        "from sparselinear import SparseLinear\n",
        "\n",
        "\n",
        "@dataclass(eq=False)\n",
        "class DisjunctiveNeuron:\n",
        "    intent: FrozenSet[str]\n",
        "    level: int\n",
        "\n",
        "    def __eq__(self, other: 'DisjunctiveNeuron'):\n",
        "        return self.intent == other.intent and self.level == other.level\n",
        "\n",
        "    def __lt__(self, other: 'DisjunctiveNeuron'):\n",
        "        return self.intent & other.intent == other.intent and self.level > other.level\n",
        "\n",
        "    def __le__(self, other: 'DisjunctiveNeuron'):\n",
        "        return self < other or self == other\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.intent, self.level))\n",
        "\n",
        "\n",
        "class ConceptNetwork:\n",
        "    def __init__(self, poset: POSet, network=None, attributes: Tuple[str] = None, targets: Tuple[str] = None):\n",
        "        self._poset = poset\n",
        "        self._network = network\n",
        "        self._attributes = attributes\n",
        "        self._targets = targets\n",
        "\n",
        "    @property\n",
        "    def poset(self) -> POSet:\n",
        "        return self._poset\n",
        "\n",
        "    @property\n",
        "    def network(self) -> torch.nn.Sequential:\n",
        "        return self._network\n",
        "\n",
        "    @property\n",
        "    def attributes(self) -> Tuple[str]:\n",
        "        return self._attributes\n",
        "\n",
        "    @property\n",
        "    def targets(self):\n",
        "        return self._targets\n",
        "\n",
        "    def trace_description(self, description: FrozenSet[str], include_targets: bool = False) -> Set[int]:\n",
        "        P = self.poset\n",
        "\n",
        "        tops_activated = [node for node in P.tops if P[node].intent & description == P[node].intent]\n",
        "        activated_nodes = set(tops_activated)\n",
        "        for node in tops_activated:\n",
        "            activated_nodes |= P.descendants(node)\n",
        "        if not include_targets:\n",
        "            activated_nodes -= set(P.bottoms)\n",
        "\n",
        "        return activated_nodes\n",
        "\n",
        "    @classmethod\n",
        "    def from_lattice(\n",
        "            cls,\n",
        "            lattice: ConceptLattice, best_concepts_indices: List[int],\n",
        "            targets: Tuple[str]\n",
        "    ):\n",
        "        assert lattice.is_monotone, 'The lattice should be monotone'\n",
        "\n",
        "        targets = tuple(targets)\n",
        "\n",
        "        attrs_tpl = tuple(lattice[lattice.bottom].intent)\n",
        "        P = cls._poset_from_best_concepts(lattice[best_concepts_indices], targets, attrs_tpl)\n",
        "        P = cls._fill_levels(P)\n",
        "        return cls(P, None, attributes=attrs_tpl, targets=targets)\n",
        "\n",
        "    def fit(\n",
        "            self,\n",
        "            X_df: 'pd.DataFrame[bool]', y: 'pd.Series[bool]',\n",
        "            loss_fn=torch.nn.CrossEntropyLoss(), nonlinearity=torch.nn.ReLU,\n",
        "            n_epochs: int = 2000\n",
        "    ):\n",
        "        X = torch.tensor(X_df[list(self.attributes)].values).float()\n",
        "        y = torch.tensor(y.values).long()\n",
        "\n",
        "        self._network = self._poset_to_network(self.poset, nonlinearity)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.network.parameters())\n",
        "\n",
        "        for t in range(n_epochs):\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = self.network(X)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def predict_proba(self, X_df: 'pd.DataFrame[bool]') -> torch.Tensor:\n",
        "        X = torch.tensor(X_df[list(self.attributes)].values).float()\n",
        "        return self.network(X)\n",
        "\n",
        "    def predict(self, X_df: 'pd.DataFrame[bool]') -> torch.Tensor:\n",
        "        return self.predict_proba(X_df).argmax(1)\n",
        "\n",
        "    def edge_weights_from_network(self) -> Dict[Tuple[int, int], float]:\n",
        "        max_level = self.poset[self.poset.bottoms[0]].level\n",
        "        nodes_per_levels = {lvl: [] for lvl in range(max_level + 1)}\n",
        "        for node_i, node in enumerate(self.poset):\n",
        "            nodes_per_levels[node.level].append(node_i)\n",
        "        nodes_per_levels = [nodes_per_levels[lvl] for lvl in range(max_level + 1)]\n",
        "\n",
        "        edge_weights = {}\n",
        "        for layer_i, nodes in enumerate(nodes_per_levels[:-1]):\n",
        "            next_nodes = nodes_per_levels[layer_i+1]\n",
        "\n",
        "            nn_layer = self.network[layer_i*2]\n",
        "            idxs = nn_layer.weight.indices().numpy().T.tolist()\n",
        "            vals = nn_layer.weight.values().numpy()\n",
        "\n",
        "            for (child_i, parent_i), v in zip(idxs, vals):\n",
        "                edge_weights[(nodes[parent_i], next_nodes[child_i])] = v\n",
        "        return edge_weights\n",
        "\n",
        "    @staticmethod\n",
        "    def _poset_from_best_concepts(\n",
        "            best_concepts: List[FormalConcept], targets: Tuple[str], attrs_tpl: Tuple[str]\n",
        "    ) -> POSet:\n",
        "        P_best = POSet(best_concepts)\n",
        "        lvls = calc_levels(P_best)[0]\n",
        "        lvls = [lvl + 1 for lvl in lvls]\n",
        "        target_lvl = max(lvls) + 1\n",
        "\n",
        "        attrs_set = set(attrs_tpl)\n",
        "\n",
        "        best_neurons = [DisjunctiveNeuron(frozenset(c.intent), lvl) for c, lvl in zip(P_best, lvls)]\n",
        "        first_level_neurons = [DisjunctiveNeuron(frozenset({m}), 0) for m in attrs_tpl]\n",
        "        last_level_neurons = [DisjunctiveNeuron(frozenset({f\"y={y}\"} | attrs_set), target_lvl) for y in targets]\n",
        "        return POSet(first_level_neurons + best_neurons + last_level_neurons)\n",
        "\n",
        "    @staticmethod\n",
        "    def _fill_levels(poset: POSet) -> POSet:\n",
        "        nodes_i = sorted(range(len(poset)), key=lambda node_i: poset[node_i].level)\n",
        "        for node_i in nodes_i:\n",
        "            children_i = poset.children(node_i)\n",
        "            if len(children_i) == 0:\n",
        "                continue\n",
        "\n",
        "            max_children_level = max([poset[child_i].level for child_i in children_i])\n",
        "            for lvl in range(poset[node_i].level+1, max_children_level):\n",
        "                poset.add(DisjunctiveNeuron(poset[node_i].intent, lvl))\n",
        "        return poset\n",
        "\n",
        "    @staticmethod\n",
        "    def _poset_to_network(poset: POSet, nonlinearity: type = torch.nn.ReLU) -> 'torch.nn.Sequential':\n",
        "        max_level = poset[poset.bottoms[0]].level\n",
        "        nodes_per_levels = {lvl: [] for lvl in range(max_level + 1)}\n",
        "        for node_i, node in enumerate(poset):\n",
        "            nodes_per_levels[node.level].append(node_i)\n",
        "        nodes_per_levels = [nodes_per_levels[lvl] for lvl in range(max_level + 1)]\n",
        "\n",
        "        connectivities = []\n",
        "        for layer_i, layer in enumerate(nodes_per_levels[1:]):\n",
        "            layer_i += 1\n",
        "            prev_layer = nodes_per_levels[layer_i - 1]\n",
        "            layer_con = [(layer.index(node), prev_layer.index(parent))\n",
        "                         for node in layer for parent in poset.parents(node)]\n",
        "            connectivities.append(layer_con)\n",
        "\n",
        "        linear_layers = []\n",
        "        for layer_i in range(max_level):\n",
        "            con = torch.tensor(connectivities[layer_i]).T\n",
        "            layer = SparseLinear(len(nodes_per_levels[layer_i]), len(nodes_per_levels[layer_i + 1]), connectivity=con)\n",
        "            linear_layers.append(layer)\n",
        "\n",
        "        layers = [layer for ll in linear_layers for layer in [ll, nonlinearity()]][:-1] + [torch.nn.Softmax(dim=1)]\n",
        "        model_sparse = torch.nn.Sequential(*layers)\n",
        "        return model_sparse\n",
        "\n",
        "\n",
        "def neuron_label_func(el_i: int, P: POSet, M: set, only_new_attrs: bool = True):\n",
        "    el = P[el_i]\n",
        "\n",
        "    if len(el.intent - M) > 0:  # if target node\n",
        "        attrs_to_show = list(el.intent - M)\n",
        "    else:\n",
        "        attrs_to_show = set(el.intent)\n",
        "        if only_new_attrs:\n",
        "            for parent_i in P.parents(el_i):\n",
        "                attrs_to_show = attrs_to_show - P[parent_i].intent\n",
        "\n",
        "        attrs_to_show = list(attrs_to_show)\n",
        "    return ','.join(attrs_to_show)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "hB6gJ09fFmi9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title import data\n",
        "\n",
        "root = 'https://hse.kamran.uz/osda23/fca/'\n",
        "\n",
        "pp = pd.read_csv(f'{root}/prepared_pp.csv')\n",
        "c  = pd.read_csv(f'{root}/prepared_c.csv')\n",
        "z  = pd.read_csv(f'{root}/prepared_z.csv')\n",
        "p  = pd.read_csv(f'{root}/prepared_p.csv')\n",
        "\n",
        "\n",
        "y_pp = pd.read_csv(f'{root}/target_pp.csv')\n",
        "y_c  = pd.read_csv(f'{root}/target_c.csv')\n",
        "y_z  = pd.read_csv(f'{root}/target_z.csv')\n",
        "y_p  = pd.read_csv(f'{root}/target_p.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train\n",
        "\n",
        "def get_train_test(X,y):\n",
        "    X.index = X.index.astype('str')\n",
        "    y.index = y.index.astype('str')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                        test_size=0.1,\n",
        "                                                        random_state=42,\n",
        "                                                        shuffle=True,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X = [pp,c,z,p]\n",
        "y = [y_pp,y_c,y_z,y_p]\n",
        "models = []\n",
        "for X_, y_ in zip(X,y):\n",
        "    m = []\n",
        "    # Split the data to train and test\n",
        "    X_train, X_test, y_train, y_test = get_train_test(X_, y_)\n",
        "\n",
        "    # Put binarized data in FormalContext and compute monotone ConceptLattice\n",
        "    K_train = FormalContext(data = X_train.values, target=y_train.values, attribute_names=X_train.columns)\n",
        "    L = ConceptLattice.from_context(K_train, algo='Sofia', is_monotone=True)\n",
        "\n",
        "    # Compute F1 score for each formal concept (assuming that an object is predicted True if it is in the extent of the concept)\n",
        "    for c in L:\n",
        "        y_preds = np.zeros(K_train.n_objects)\n",
        "        y_preds[list(c.extent_i)] = 1\n",
        "        c.measures = dict(f1_score=f1_score(y_train, y_preds))\n",
        "\n",
        "    # Select indices of the best concepts from the lattice\n",
        "    best_concepts = list(L.measures['f1_score'].argsort()[::-1])\n",
        "    for i in range(len(best_concepts)):\n",
        "        if len({g_i for c in L[best_concepts[:i]] for g_i in c.extent_i})==K_train.n_objects:\n",
        "            best_concepts = best_concepts[:i]\n",
        "            break\n",
        "\n",
        "    # Construct neural network based on concept lattice\n",
        "    cn = nl.ConceptNetwork.from_lattice(L, best_concepts, sorted(set(y_train)))\n",
        "    # cn.fit(X_train, y_train)\n",
        "    m = [cn, K_train,L,[X_train, X_test, y_train, y_test]]\n",
        "    models += [m]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TCZQjXseP6Nw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of learned Latice\n",
        "\n",
        "models[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqxu0sVLaKOX",
        "outputId": "3a4983f0-561d-4738-a739-982055b51c4e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FormalContext (307 objects, 19 attributes, 1995 connections)\n",
              "   |sex|island_Biscoe|island_Dream|island_Torgersen|year_2007|...|flipper_length_mm_(192.0, 209.333]|flipper_length_mm_(209.333, 231.0]|body_mass_g_(2699.999, 3700.0]|body_mass_g_(3700.0, 4550.0]|body_mass_g_(4550.0, 6300.0]|\n",
              "0  |  X|             |           X|                |         |...|                                 X|                                  |                             X|                            |                            |\n",
              "1  |   |             |           X|                |         |...|                                 X|                                  |                             X|                            |                            |\n",
              "2  |   |             |           X|                |        X|...|                                 X|                                  |                             X|                            |                            |\n",
              "3  |  X|             |           X|                |         |...|                                  |                                  |                             X|                            |                            |\n",
              "4  |   |            X|            |                |         |...|                                  |                                 X|                              |                            |                           X|\n",
              "5  |  X|             |           X|                |         |...|                                  |                                  |                             X|                            |                            |\n",
              "6  |  X|             |            |               X|        X|...|                                  |                                  |                             X|                            |                            |\n",
              "7  |  X|            X|            |                |         |...|                                  |                                  |                             X|                            |                            |\n",
              "8  |  X|             |            |               X|         |...|                                  |                                  |                             X|                            |                            |\n",
              "9  |   |             |           X|                |         |...|                                 X|                                  |                              |                           X|                            |\n",
              ".................................................................................................................................................................................................................................\n",
              ".................................................................................................................................................................................................................................\n",
              "297|   |            X|            |                |        X|...|                                  |                                 X|                              |                            |                           X|\n",
              "298|   |             |           X|                |         |...|                                 X|                                  |                              |                           X|                            |\n",
              "299|   |             |            |               X|         |...|                                  |                                 X|                              |                           X|                            |\n",
              "300|   |             |            |               X|         |...|                                 X|                                  |                             X|                            |                            |\n",
              "301|  X|             |            |               X|        X|...|                                 X|                                  |                             X|                            |                            |\n",
              "302|   |            X|            |                |         |...|                                 X|                                  |                              |                           X|                            |\n",
              "303|   |             |           X|                |         |...|                                 X|                                  |                             X|                            |                            |\n",
              "304|   |            X|            |                |         |...|                                 X|                                  |                              |                           X|                            |\n",
              "305|  X|            X|            |                |         |...|                                  |                                 X|                              |                            |                           X|\n",
              "306|  X|             |           X|                |         |...|                                 X|                                  |                             X|                            |                            |"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "EQSb6l_nu8KH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title plot\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "def plot_cn(cn):\n",
        "    fig, ax = plt.subplots(figsize=(15,5))\n",
        "    vis = LineVizNx(node_label_font_size=14, node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn.attributes))+'\\n\\n')\n",
        "    vis.init_mover_per_poset(cn.poset)\n",
        "    edge_weights = cn.edge_weights_from_network()\n",
        "\n",
        "    vis.draw_poset(\n",
        "        cn.poset, ax=ax,\n",
        "        flg_node_indices=False,\n",
        "        node_label_func=lambda el_i, P: nl.neuron_label_func(el_i, P, set(cn.attributes), only_new_attrs=True)+'\\n\\n',\n",
        "        edge_color=[edge_weights[edge] for edge in cn.poset.to_networkx().edges],\n",
        "        edge_cmap=plt.cm.RdBu,\n",
        "    )\n",
        "    nx.draw_networkx_edge_labels(cn.poset.to_networkx(), vis.mover.pos, {k: f\"{v:.1f}\" for k,v in edge_weights.items()}, label_pos=0.7)\n",
        "\n",
        "    plt.title('Neural network with fitted edge weights', size=24, x=0.05, loc='left')\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust()\n",
        "    plt.savefig('fitted_network.png')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}